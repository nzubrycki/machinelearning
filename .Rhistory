# First step is to clear the environment
rm(list=ls())
# Next we load our data
# Note that our working directory has been set to our lproject folder where this file, and the data are located
data <- read.csv(file = "recipeData.csv", na.strings=c("N/A"))
# Note that our KNN algorithm will not work with non-numeric values, so we can remove columns that we do not need
# We are using the same exact data set with our neural net as well, se we follow the same steps
data$SugarScale <- NULL
data$BrewMethod <- NULL
data$PrimingMethod <- NULL
data$PrimingAmount <- NULL
setwd("C:/Users/nzubrycki/OneDrive/Documents/CS 513/R/project/machinelearning")
# First step is to clear the environment
rm(list=ls())
# Next we load our data
# Note that our working directory has been set to our lproject folder where this file, and the data are located
data <- read.csv(file = "recipeData.csv", na.strings=c("N/A"))
# Note that our KNN algorithm will not work with non-numeric values, so we can remove columns that we do not need
# We are using the same exact data set with our neural net as well, se we follow the same steps
data$SugarScale <- NULL
data$BrewMethod <- NULL
data$PrimingMethod <- NULL
data$PrimingAmount <- NULL
# Its a LOT of data so we are simply going to remove any row with NA's
data <- na.omit(data)
# Now we can separate the data into testing and training data
# We still have a lot of data, so we will be using a 50/50 split (taking every other observation)
every_other <- seq(1, nrow(data), by=2)
test_data <- data[every_other,]
train_data <- data[-every_other,]
dist<-dist(data[,-c(1,2,3,4,5,19)])
hclust_results<-hclust(dist)
hclust_2<-cutree(hclust_results,2)
table(hclust_results,data[,4])
kmeans_2<- kmeans(data[,-c(1,2,3,4,5,19)],176,nstart = 10)
kmeans_2$cluster
table(kmeans_2$cluster,data[,4])
set.seed(456)
kmeans_2<- kmeans(data[,-c(1,2,3,4,5,19)],176,nstart = 10)
kmeans_2$cluster
table(kmeans_2$cluster,data[,4])
?kmeans
kmeans_2
# First step is to clear the environment
rm(list=ls())
# Next we load our data
# Note that our working directory has been set to our lproject folder where this file, and the data are located
data <- read.csv(file = "recipeData.csv", na.strings=c("N/A"))
# Note that our KNN algorithm will not work with non-numeric values, so we can remove columns that we do not need
# We are using the same exact data set with our neural net as well, se we follow the same steps
data$SugarScale <- NULL
data$BrewMethod <- NULL
data$PrimingMethod <- NULL
data$PrimingAmount <- NULL
# Its a LOT of data so we are simply going to remove any row with NA's
data <- na.omit(data)
# Now we can separate the data into testing and training data
# We still have a lot of data, so we will be using a 50/50 split (taking every other observation)
every_other <- seq(1, nrow(data), by=2)
test_data <- data[every_other,]
train_data <- data[-every_other,]
set.seed(456)
kmeans<- kmeans(data[,-c(1,2,3,4,5,19)],176,nstart = 10)
kmeans
table(kmeans$cluster,data[,4])
table(kmeans$cluster, data$Style)
kmeans<- kmeans(data[,-c(1,2,3,4,5,19)],7,nstart = 10)
kmeans
table(kmeans$cluster, data$Style)
kmeans<- kmeans(data[,-c(1,2,3,4,5,19)],5,nstart = 10)
kmeans
table(kmeans$cluster, data$Style)
?mfv
?mfv()
install.packages("mfv")
library("mfv")
install.packages('modeest')
library('modeest')
mlv(data$Style)
mlv(data$StyleID)
View(data)
mode_styleID <- mlv(data$StyleID)
mode_styleID$M
mode_styleID$x
kmeans$cluster[,1]
plot(kmeans)
install.packages('plot.kmeans')
library('plot.kmeans')
plot(data$Style, kmeans$cluster)
kmeans$cluster[1,1]
kmeans$cluster
kmeans$cluster[1:"70531"]
kmeans$cluster
getOption("max.print")
# First step is to clear the environment
rm(list=ls())
# Next we load our data
# Note that our working directory has been set to our lproject folder where this file, and the data are located
data <- read.csv(file = "recipeData.csv", na.strings=c("N/A"))
# Note that our KNN algorithm will not work with non-numeric values, so we can remove columns that we do not need
# We are using the same exact data set with our neural net as well, se we follow the same steps
data$SugarScale <- NULL
data$BrewMethod <- NULL
data$PrimingMethod <- NULL
data$PrimingAmount <- NULL
# Its a LOT of data so we are simply going to remove any row with NA's
data <- na.omit(data)
# Now we can separate the data into testing and training data
# We still have a lot of data, so we will be using a 50/50 split (taking every other observation)
every_other <- seq(1, nrow(data), by=2)
test_data <- data[every_other,]
train_data <- data[-every_other,]
library('C50')
# c50 classification
C50_class <- C5.0( as.factor(Style)~.,data=train_data[,c(-1,-2,-3,-5,-19)] )
install.packages('c50')
library('C50')
install.packages('c50')
install.packages(c("car", "lme4", "lmtest", "robustbase"))
install.packages("C50")
library('C50')
# c50 classification
C50_class <- C5.0( as.factor(Style)~.,data=train_data[,c(-1,-2,-3,-5,-19)] )
C50_class
# general information about the tree
summary(C50_class)
dev.off()
plot(C50_class)
library(randomForest)
install.packages("randomForest")
library(randomForest)
fit <- randomForest( Style~., data=train_data, importance=TRUE, ntree=1000)
View(data)
?C5.0
library(randomForest)
set.seed(456)
fit <- randomForest( Style~., data=train_data, importance=TRUE, ntree=1000)
bin1 <- ifelse(data$StyleID<=50,1,0)
bin2 <- ifelse(data$StyleID>50<=100,1,0)
bin3 <- ifelse(data$StyleID>100<=150,1,0)
bin2 <- ifelse(data$StyleID>50 && data$StyleID<=100,1,0)
bin3 <- ifelse(data$StyleID>100 && data$StyleID<=150,1,0)
bin4 <- ifelse(data$StyleID>150,1,0)
bin2 <- ifelse(data$StyleID>50 & data$StyleID<=100,1,0)
bin3 <- ifelse(data$StyleID>100 & data$StyleID<=150,1,0)
bin1
install.packages("dplyr")
# install and load packages
#install.packages('randomForest')
#install.packages("dplyr")
library(dplyr)
bin1 <- filter(data$StyleID<=50)
bin1 <- filter(data, StyleID<=50)
View(bin1)
bin2 <- filter(data, StyleID>50 & StyleID<=100)
View(bin2)
bin3 <- filter(data, StyleID>100 & StyleID<=150)
bin4 <- filter(data, StyleID>150)
sum(nrow(bin1),nrow(bin2),nrow(bin3),nrow(bin4))
testbin1 <- bin1[every_other,]
trainbin1 <- bin1[-every_other,]
View(bin1)
View(testbin1)
everyother1 <- seq(1, nrow(bin1), by=2)
everyother1 <- seq(1, nrow(bin1), by=2)
testbin1 <- bin1[everyother1,]
trainbin1 <- bin1[-everyother1,]
everyother2 <- seq(1, nrow(bin2), by=2)
testbin2 <- bin2[everyother2,]
trainbin2 <- bin2[-everyother2,]
everyother3 <- seq(1, nrow(bin3), by=2)
testbin3 <- bin3[everyother3,]
trainbin3 <- bin3[-everyother3]
everyother4 <- seq(1, nrow(bin4), by=2)
testbin4 <- bin4[everyother4,]
trainbin4 <- bin4[-everyother4,]
fit_bin1 <- randomForest(Style~., data = trainbin1, importance=TRUE, ntree=1000)
fit_bin1 <- randomForest(StyleID~., data = trainbin1, importance=TRUE, ntree=1000)
View(bin1)
str(bin1)
# First step is to clear the environment
rm(list=ls())
# Next we load our data
# Note that our working directory has been set to our lproject folder where this file, and the data are located
data <- read.csv(file = "recipeData.csv", na.strings=c("N/A"))
# Note that our KNN algorithm will not work with non-numeric values, so we can remove columns that we do not need
# We are using the same exact data set with our neural net as well, se we follow the same steps
data$SugarScale <- NULL
data$BrewMethod <- NULL
data$PrimingMethod <- NULL
data$PrimingAmount <- NULL
# Its a LOT of data so we are simply going to remove any row with NA's
data <- na.omit(data)
# install and load packages
#install.packages('randomForest')
#install.packages("dplyr")
library(dplyr)
library(randomForest)
# separate data into bins so we can test with the random forest
bin1 <- filter(data, StyleID<=50)
bin2 <- filter(data, StyleID>50 & StyleID<=100)
bin3 <- filter(data, StyleID>100 & StyleID<=150)
bin4 <- filter(data, StyleID>150)
# check to make sure that we filtered properly, sum should equal 7053
sum(nrow(bin1),nrow(bin2),nrow(bin3),nrow(bin4))
# set seed for random forest
set.seed(456)
# get testing and training data for each bin
everyother1 <- seq(1, nrow(bin1), by=2)
testbin1 <- bin1[everyother1,]
trainbin1 <- bin1[-everyother1,]
everyother2 <- seq(1, nrow(bin2), by=2)
testbin2 <- bin2[everyother2,]
trainbin2 <- bin2[-everyother2,]
everyother3 <- seq(1, nrow(bin3), by=2)
testbin3 <- bin3[everyother3,]
trainbin3 <- bin3[-everyother3]
everyother4 <- seq(1, nrow(bin4), by=2)
testbin4 <- bin4[everyother4,]
trainbin4 <- bin4[-everyother4,]
fit_bin1 <- randomForest(StyleID~., data = trainbin1[], importance=TRUE, ntree=1000)
str(bin1)
data$Name <- NULL
data$URL <- NULL
# Its a LOT of data so we are simply going to remove any row with NA's
data <- na.omit(data)
# install and load packages
#install.packages('randomForest')
#install.packages("dplyr")
library(dplyr)
library(randomForest)
# separate data into bins so we can test with the random forest
bin1 <- filter(data, StyleID<=50)
bin2 <- filter(data, StyleID>50 & StyleID<=100)
bin3 <- filter(data, StyleID>100 & StyleID<=150)
bin4 <- filter(data, StyleID>150)
# check to make sure that we filtered properly, sum should equal 7053
sum(nrow(bin1),nrow(bin2),nrow(bin3),nrow(bin4))
# set seed for random forest
set.seed(456)
# get testing and training data for each bin
everyother1 <- seq(1, nrow(bin1), by=2)
testbin1 <- bin1[everyother1,]
trainbin1 <- bin1[-everyother1,]
everyother2 <- seq(1, nrow(bin2), by=2)
testbin2 <- bin2[everyother2,]
trainbin2 <- bin2[-everyother2,]
everyother3 <- seq(1, nrow(bin3), by=2)
testbin3 <- bin3[everyother3,]
trainbin3 <- bin3[-everyother3]
everyother4 <- seq(1, nrow(bin4), by=2)
testbin4 <- bin4[everyother4,]
trainbin4 <- bin4[-everyother4,]
fit_bin1 <- randomForest(StyleID~., data = trainbin1[], importance=TRUE, ntree=1000)
data$Style <- NULL
# Its a LOT of data so we are simply going to remove any row with NA's
data <- na.omit(data)
# install and load packages
#install.packages('randomForest')
#install.packages("dplyr")
library(dplyr)
library(randomForest)
# separate data into bins so we can test with the random forest
bin1 <- filter(data, StyleID<=50)
bin2 <- filter(data, StyleID>50 & StyleID<=100)
bin3 <- filter(data, StyleID>100 & StyleID<=150)
bin4 <- filter(data, StyleID>150)
# check to make sure that we filtered properly, sum should equal 7053
sum(nrow(bin1),nrow(bin2),nrow(bin3),nrow(bin4))
# set seed for random forest
set.seed(456)
# get testing and training data for each bin
everyother1 <- seq(1, nrow(bin1), by=2)
testbin1 <- bin1[everyother1,]
trainbin1 <- bin1[-everyother1,]
everyother2 <- seq(1, nrow(bin2), by=2)
testbin2 <- bin2[everyother2,]
trainbin2 <- bin2[-everyother2,]
everyother3 <- seq(1, nrow(bin3), by=2)
testbin3 <- bin3[everyother3,]
trainbin3 <- bin3[-everyother3]
everyother4 <- seq(1, nrow(bin4), by=2)
testbin4 <- bin4[everyother4,]
trainbin4 <- bin4[-everyother4,]
fit_bin1 <- randomForest(StyleID~., data = trainbin1[], importance=TRUE, ntree=1000)
View(testbin1)
importance(fit_bin1)
varImpPlot(fit_bin1)
prediction_bin1 <- predict(fit_bin1,testbin1)
table(actual=testbin1$StyleID, prediction_bin1)
wrong_bin1 <- (testbin1[,2]!=prediction_bin1)
errorrate_bin1 <- sum(wrong_bin1)/length(wrong_bin1)
errorrate_bin1
prediction_bin1 <- predict(fit_bin1,testbin1)
prediction_bin1 <- round(prediction_bin1)
table(actual=testbin1$StyleID, prediction_bin1)
wrong_bin1 <- (testbin1[,2]!=prediction_bin1)
errorrate_bin1 <- sum(wrong_bin1)/length(wrong_bin1)
errorrate_bin1
##################################################################################################
# bin 2
fit_bin2 <- randomForest(StyleID~., data = trainbin2[], importance=TRUE, ntree=1000)
importance(fit_bin2)
varImpPlot(fit_bin2)
prediction_bin2 <- predict(fit_bin2,testbin2)
# because we are predicting ID's we must round our predictions
prediction_bin2 <- round(prediction_bin2)
#test accuracy of the algorithm
wrong_bin2 <- (testbin2[,2]!=prediction_bin2)
errorrate_bin2 <- sum(wrong_bin2)/length(wrong_bin2)
errorrate_bin2
##################################################################################################
# bin 3
fit_bin3 <- randomForest(StyleID~., data = trainbin3[], importance=TRUE, ntree=1000)
importance(fit_bin3)
varImpPlot(fit_bin3)
View(bin3)
prediction_bin3 <- predict(fit_bin3,testbin3)
# because we are predicting ID's we must round our predictions
prediction_bin3 <- round(prediction_bin3)
#test accuracy of the algorithm
wrong_bin3 <- (testbin3[,2]!=prediction_bin3)
errorrate_bin3 <- sum(wrong_bin3)/length(wrong_bin3)
errorrate_bin3
##################################################################################################
# bin 4
fit_bin4 <- randomForest(StyleID~., data = trainbin4[], importance=TRUE, ntree=1000)
importance(fit_bin4)
varImpPlot(fit_bin4)
prediction_bin4 <- predict(fit_bin4,testbin4)
# because we are predicting ID's we must round our predictions
prediction_bin4 <- round(prediction_bin4)
#test accuracy of the algorithm
wrong_bin4 <- (testbin4[,2]!=prediction_bin4)
errorrate_bin4 <- sum(wrong_bin4)/length(wrong_bin4)
errorrate_bin4
##################################################################################################
# bin 3
fit_bin3 <- randomForest(StyleID~., data = trainbin3[], importance=TRUE, ntree=1000)
importance(fit_bin3)
##################################################################################################
# bin 3
fit_bin3 <- randomForest(StyleID~., data = trainbin3[], importance=TRUE, ntree=1000)
importance(fit_bin3)
varImpPlot(fit_bin3)
prediction_bin3 <- predict(fit_bin3,testbin3)
# because we are predicting ID's we must round our predictions
prediction_bin3 <- round(prediction_bin3)
#test accuracy of the algorithm
wrong_bin3 <- (testbin3[,2]!=prediction_bin3)
errorrate_bin3 <- sum(wrong_bin3)/length(wrong_bin3)
errorrate_bin3
# First step is to clear the environment
rm(list=ls())
# Next we load our data
# Note that our working directory has been set to our lproject folder where this file, and the data are located
data <- read.csv(file = "recipeData.csv", na.strings=c("N/A"))
# Note that our KNN algorithm will not work with non-numeric values, so we can remove columns that we do not need
# We must eliminate more columns this time to appease the random forest algorithm
#(we can't have a column with factors of more than 53 categories)
data$SugarScale <- NULL
data$BrewMethod <- NULL
data$PrimingMethod <- NULL
data$PrimingAmount <- NULL
# these are the extra removals
data$Name <- NULL
data$URL <- NULL
data$Style <- NULL
data$UserId <- NULL
# Its a LOT of data so we are simply going to remove any row with NA's
data <- na.omit(data)
# First step is to clear the environment
rm(list=ls())
# Next we load our data
# Note that our working directory has been set to our lproject folder where this file, and the data are located
data <- read.csv(file = "recipeData.csv", na.strings=c("N/A"))
# Note that our KNN algorithm will not work with non-numeric values, so we can remove columns that we do not need
# We must eliminate more columns this time to appease the random forest algorithm
#(we can't have a column with factors of more than 53 categories)
data$SugarScale <- NULL
data$BrewMethod <- NULL
data$PrimingMethod <- NULL
data$PrimingAmount <- NULL
# Its a LOT of data so we are simply going to remove any row with NA's
data <- na.omit(data)
# these are the extra removals
data$Name <- NULL
data$URL <- NULL
data$Style <- NULL
data$UserId <- NULL
# install and load packages
#install.packages('randomForest')
#install.packages("dplyr")
library(dplyr)
library(randomForest)
# separate data into bins so we can test with the random forest
bin1 <- filter(data, StyleID<=50)
bin2 <- filter(data, StyleID>50 & StyleID<=100)
bin3 <- filter(data, StyleID>100 & StyleID<=150)
bin4 <- filter(data, StyleID>150)
# check to make sure that we filtered properly, sum should equal 7053
sum(nrow(bin1),nrow(bin2),nrow(bin3),nrow(bin4))
# set seed for random forest
set.seed(456)
# get testing and training data for each bin
everyother1 <- seq(1, nrow(bin1), by=2)
testbin1 <- bin1[everyother1,]
trainbin1 <- bin1[-everyother1,]
everyother2 <- seq(1, nrow(bin2), by=2)
testbin2 <- bin2[everyother2,]
trainbin2 <- bin2[-everyother2,]
everyother3 <- seq(1, nrow(bin3), by=2)
testbin3 <- bin3[everyother3,]
trainbin3 <- bin3[-everyother3]
everyother4 <- seq(1, nrow(bin4), by=2)
testbin4 <- bin4[everyother4,]
trainbin4 <- bin4[-everyother4,]
##################################################################################################
# bin 1
fit_bin1 <- randomForest(StyleID~., data = trainbin1[], importance=TRUE, ntree=1000)
importance(fit_bin1)
varImpPlot(fit_bin1)
prediction_bin1 <- predict(fit_bin1,testbin1)
# because we are predicting ID's we must round our predictions
prediction_bin1 <- round(prediction_bin1)
#test accuracy of the algorithm
wrong_bin1 <- (testbin1[,2]!=prediction_bin1)
errorrate_bin1 <- sum(wrong_bin1)/length(wrong_bin1)
errorrate_bin1
##################################################################################################
# bin 2
fit_bin2 <- randomForest(StyleID~., data = trainbin2[], importance=TRUE, ntree=1000)
importance(fit_bin2)
varImpPlot(fit_bin2)
prediction_bin2 <- predict(fit_bin2,testbin2)
# because we are predicting ID's we must round our predictions
prediction_bin2 <- round(prediction_bin2)
#test accuracy of the algorithm
wrong_bin2 <- (testbin2[,2]!=prediction_bin2)
errorrate_bin2 <- sum(wrong_bin2)/length(wrong_bin2)
errorrate_bin2
##################################################################################################
# bin 3
fit_bin3 <- randomForest(StyleID~., data = trainbin3[], importance=TRUE, ntree=1000)
importance(fit_bin3)
varImpPlot(fit_bin3)
prediction_bin3 <- predict(fit_bin3,testbin3)
# because we are predicting ID's we must round our predictions
prediction_bin3 <- round(prediction_bin3)
#test accuracy of the algorithm
wrong_bin3 <- (testbin3[,2]!=prediction_bin3)
errorrate_bin3 <- sum(wrong_bin3)/length(wrong_bin3)
errorrate_bin3
##################################################################################################
# bin 4
fit_bin4 <- randomForest(StyleID~., data = trainbin4[], importance=TRUE, ntree=1000)
importance(fit_bin4)
varImpPlot(fit_bin4)
prediction_bin4 <- predict(fit_bin4,testbin4)
# because we are predicting ID's we must round our predictions
prediction_bin4 <- round(prediction_bin4)
#test accuracy of the algorithm
wrong_bin4 <- (testbin4[,2]!=prediction_bin4)
errorrate_bin4 <- sum(wrong_bin4)/length(wrong_bin4)
errorrate_bin4
every_other <- seq(1, nrow(data), by=2)
test_data <- data[every_other,]
train_data <- data[-every_other,]
fit_data <- randomForest(StyleID~., data = train_data[], importance=TRUE, ntree=1000)
importance(fit_data)
varImpPlot(fit_data)
prediction_data <- predict(fit_data, test_data)
prediction_data <- round(prediction_data)
wrong_data <- (test_data[,2]!=prediction_data)
errorrate_data <- sum(wrong_data)/length(wrong_data)
errorrate_data
